---
layout: archive
title: "Selected Publications / Preprints (* Equal Contribution.)"
permalink: /publications/
author_profile: true
---

<b>From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors</b> <br>
Zhengshen Zhang, Hao Li, Yalun Dai, <b>Zhengbang Zhu</b>, Lei Zhou, Chenchen Liu, Dong Wang, Francis EH Tay, Sijin Chen, Ziwei Liu, Yuxiao Liu, Xinghang Li, Pan Zhou. <br>
<b>arXiv Preprint</b>. [<a href="https://arxiv.org/abs/2510.17439">paper</a>] [<a href="https://falcon-vla.github.io">website</a>]

<b>Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots</b> <br>
Minghuan Liu\*, <b>Zhengbang Zhu\*</b>, Xiaoshen Han\*, Peng Hu\*, Haotong Lin, Xinyao Li, Jingxiao Chen, Jiafeng Xu, Yichu Yang, Yunfeng Lin, Xinghang Li, Yong Yu, Weinan Zhang, Tao Kong, Bingyi Kang. <br>
<b>arXiv Preprint</b>. [<a href="https://arxiv.org/abs/2503.05808">paper</a>] [<a href="https://github.com/ByteDance-Seed/manip-as-in-sim-suite">code</a>] [<a href="https://manipulation-as-in-simulation.github.io">website</a>]

<b>Drivegen: Towards Infinite Diverse Traffic Scenarios with Large Models</b> <br>
Shenyu Zhang, Jiaguo Tian, <b>Zhengbang Zhu</b>, Shan Huang, Jucheng Yang, Weinan Zhang. <br>
<b>IROS 2025</b>. [<a href="https://arxiv.org/abs/2503.05808">paper</a>]

<b>RHINO: Learning Real-Time Humanoid-Human-Object Interaction from Human Demonstrations</b> <br>
Jingxiao Chen\*, Xinyao Li\*, Jiahang Cao\*, <b>Zhengbang Zhu</b>, Wentao Dong, Minghuan Liu, Ying Wen, Yong Yu, Liqing Zhang, Weinan Zhang. <br>
<b>arXiv Preprint</b>. [<a href="http://arxiv.org/abs/2502.13134">paper</a>] [<a href="https://github.com/TimerChen/RHINO">code</a>] [<a href="https://humanoid-interaction.github.io">website</a>]

<b>Reconstruction-Guided Policy: Enhancing Decision-Making through Agent-Wise State Consistency</b> <br>
Liang Qifan, Yixiang Shan, Haipeng Liu, <b>Zhengbang Zhu</b>, Ting Long, Weinan Zhang, Yuan Tian. <br>
<b>ICLR 2025</b>. [<a href="https://openreview.net/forum?id=Y8L5RB4GWb">paper</a>]
<br>

<b>Contrastive Diffuser: Planning Towards High Return States via Contrastive Learning</b> <br>
Yixiang Shan, <b>Zhengbang Zhu</b>, Ting Long, Qifan Liang, Yi Chang, Weinan Zhang, Liang Yin. <br>
<b>ICLR 2025</b>. [<a href="https://arxiv.org/abs/2402.02772">paper</a>]
<br>

<b>MADiff: Offline Multi-agent Learning with Diffusion Models</b> <br> 
<b>Zhengbang Zhu</b>, Minghuan Liu, Liyuan Mao, Bingyi Kang, Minkai Xu, Yong Yu, Stefano Ermon, Weinan Zhang. <br> 
<b>NeurIPS 2024</b>. [<a href="https://arxiv.org/abs/2305.17330">paper</a>] [<a href="https://github.com/zbzhu99/madiff">code</a>] 
<br>

<b>DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching</b> <br>
Guanghe Li, Yixiang Shan, <b>Zhengbang Zhu</b>, Ting Long, Weinan Zhang. <br>
<b>ICML 2024</b>. [<a href="https://arxiv.org/abs/2402.02439">paper</a>] [<a href="https://github.com/guangheli12/DiffStitch">code</a>]
<br>

<b>Diffusion Models for Reinforcement Learning: A Survey</b> <br>
<b>Zhengbang Zhu</b>, Hanye Zhao, Haoran He, Yichao Zhong, Shenyu Zhang, Haoquan Guo, Tingting Chen, Weinan Zhang. <br>
<b>arXiv Preprint</b>. [<a href="https://arxiv.org/abs/2311.01223">paper</a>]
<br>

<b>RITA: Boost Driving Simulators with Realistic Interactive Traffic Flow</b> <br>
<b>Zhengbang Zhu\*</b>, Shenyu Zhang\*, Yuzheng Zhuang\*, Yuecheng Liu, Minghuan Liu, Liyuan Mao, Ziqing Gong, Shixiong Kai, Qiang Gu, Bin Wang, Siyuan Cheng, Xinyu Wang, Jianye Hao, Yong Yu. <br>
<b>DAI 2023</b>. <font color="red"><em><strong>(Best Student Paper Award)</strong></em></font>. [<a href="https://arxiv.org/abs/2211.03408">paper</a>]
<br>

<b>Understanding or Manipulation: Rethinking Online Performance Gains of Modern Recommender Systems</b> <br>
<b>Zhengbang Zhu</b>, Rongjun Qin, Junjie Huang, Xinyi Dai, Yang Yu, Yong Yu, Weinan Zhang. <br>
<b>ACM Transactions on Information Systems (TOIS) 2024</b>. [<a href="https://arxiv.org/abs/2210.05662">paper</a>]
<br>

<b>Plan Your Target and Learn Your Skills: Transferable State-Only Imitation Learning via Decoupled Policy Optimization</b> <br>
Minghuan Liu, <b>Zhengbang Zhu</b>, Yuzheng Zhuang, Weinan Zhang, Jianye Hao, Yong Yu, Jun Wang. <br>
<b>ICML 2022</b>. [<a href="https://arxiv.org/abs/2203.02214">paper</a>] [<a href="https://github.com/apexrl/DePO">code</a>] [<a href="https://decoupled-policy-optimization.github.io/">website</a>]
<br>

<b>SMARTS: Scalable Multi-agent Reinforcement Learning Training School for Autonomous Driving</b> <br>
Ming Zhou, Jun Luo, Julian Villella, Yaodong Yang, David Rusu, Jiayu Miao, Weinan Zhang, Montgomery Alban, Iman Fadakar, Zheng Chen, Aurora Chongxi Huang, Ying Wen, Kimia Hassanzadeh, Daniel Graves, Dong Chen, <b>Zhengbang Zhu</b>, Nhat Nguyen, Mohamed Elsayed, Kun Shao, Sanjeevan Ahilan, Baokuan Zhang, Jiannan Wu, Zhengang Fu, Kasra Rezaee, Peyman Yadmellat, Mohsen Rohani, Nicolas Perez Nieves, Yihan Ni, Seyedershad Banijamali, Alexander Cowen Rivers, Zheng Tian, Daniel Palenicek, Hongbo Zhang, Wulong Liu, Jianye Hao, Jun Wang. <br>
<b>CoRL 2020</b>. <font color="red"><em><strong>(Best System Paper Award)</strong></em></font>. [<a href="https://arxiv.org/abs/2010.09776">paper</a>] [<a href="https://github.com/huawei-noah/SMARTS">code</a>]
